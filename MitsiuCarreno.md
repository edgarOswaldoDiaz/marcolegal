# Regulaciones legales y uso de datos digitales en el contexto de la inteligencia artifical
Los avances tecnológicos cada vez más frecuentemente se convierten en fuerzas disruptivas a las que la sociedad tiene que adaptarse, sin embargo este empuje lleva consigo riesgos que se deben explorar, entender y regular.         
Los avances en Inteligencia artificial y big data han traído grandes beneficios y herramientas sorprendentes puestas a disposición masiva, comunidades del mundo sin importar su raza, edad, creencia, etc, pueden hacer uso de herramientas como ChatGPT, asistentes de aula virtual, edición automática de fotografías, por nombrar algunas. La tecnología ha impactado sectores que parecen ser totalmente aislados como entretenimiento, salud, educación, productividad. Pero este impacto de no ser regulado puede promover malas prácticas que impactan negativamente los derechos de las personas.         
El uso de herramientas que integren tecnología de inteligencia artificial deben ser capaces de ofrecer mecanismos de transparencia y explicabilidad, esto implica proporcionar información clara sobre cómo se emplean los datos para generar toma de decisiones así como el impacto derivado de dichas decisiones. Un ejemplo claro es la integración de Inteligencia artificial en contratación y reclutamiento, en el que aceptar o rechazar a un candidato debe poder ser explicable.         
Otro principio ético que se debe considerar en el uso de tecnologías de inteligencia artificial es el aseguramiento de la privacidad y seguridad de los datos que se emplean durante el entrenamiento así como los datos generados del uso mismo de la herramienta. Al respecto se deben crear leyes y marcos regulatorios que permitan a los usuarios entender y decidir cómo se recopila su información, siempre respetando y protegiendo los datos personales, previniendo accesos no autorizados y garantizando la confidencialidad de la información.         
Además se deben establecer normativas de responsabilidad y rendición de cuentas que definan claramente las responsabilidades de cada uno de los actores involucrados (desarrolladores, empresas comercializadoras, usuarios, etc), de manera que se puedan atribuir responsabilidades en caso de daños o consecuencias negativas del uso de herramientas inteligentes. La rendición de cuentas es esencial para promover la confianza y la responsabilidad ética en el desarrollo y uso de la inteligencia artificial.        
Es obligación de los gobiernos establecer marcos regulatorios a través de leyes y regulaciones que fomenten el uso seguro de tecnología,  que permitan aprovechar los grandes beneficios de la tecnología, pero encuadrandola en un contexto que garantice la seguridad, equidad y justicia sobre los beneficios que ofrece.

![avatar](./assets/mit-avat.png)
Mitsiu Alejandro Carreño Sarabia
